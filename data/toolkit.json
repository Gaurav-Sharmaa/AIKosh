[
  {
    "id": 1,
    "title": "ARX",
    "description": "Enterprise-grade tool for anonymizing structured sensitive personal information (PII).",
    "image_url": null,
    "overview": "ARX is a comprehensive open-source software designed for the anonymization of structured data. It supports a wide array of privacy models, including k-anonymity, l-diversity, t-closeness, and differential privacy. ARX is particularly suited for scenarios involving tabular datasets, such as databases and spreadsheets, where sensitive information must be transformed to prevent re-identification. The tool offers advanced data transformation, risk analysis, and data utility assessment capabilities, making it a preferred choice in healthcare, government, and research domains for privacy-preserving data publishing.",
    "key_capabilities": "Privacy Model Support: Implements advanced privacy models like k-anonymity, l-diversity, t-closeness, δ-presence, and differential privacy.\nRisk Analysis: Provides detailed privacy risk analysis, including prosecutor, journalist, and marketer attacker models.\nData Utility Preservation: Supports utility metrics and transformation analysis to maintain the usefulness of anonymized data.\nCustomizable Generalization & Suppression: Offers user-configurable transformation rules for quasi-identifiers.\nInteractive GUI & Programmatic API: Provides a powerful graphical user interface and Java-based APIs for automation.\nImport/Export Formats: Supports multiple data formats including CSV, Excel, and relational databases.\nBatch Processing: Facilitates anonymization of large datasets using scriptable command-line interfaces.\nDocumentation and Tutorials: Extensive documentation with examples for different use cases and compliance needs.",
    "why_it_is_included": "ARX is included in AIKosh for its robust anonymization capabilities in structured data contexts. Unlike tools focused on unstructured data, ARX excels in transforming tabular datasets while maintaining a balance between privacy protection and data utility. It aligns well with data governance requirements such as GDPR, HIPAA, and open data publishing. ARX empowers users to anonymize datasets pre-contribution to ensure compliance with privacy standards while retaining analytical value.",
    "resources_on_getting_started": "Official Website: https://arx.deidentifier.org/\nGitHub Repository: https://github.com/arx-deidentifier/arx\nDocumentation: https://arx.deidentifier.org/anonymization-tool/\nGUI Download: Available for Windows, Linux, and macOS",
    "license_and_compliance": "License: Apache License 2.0\nARX is open-source and can be used for research, commercial, or non-commercial use cases. It complies with data privacy regulations and is suitable for publishing anonymized datasets.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v3.9.1 (as of November 2022)\nGitHub Stars: 657+\nActive Contributors: 28+\nLast Updated: November 2022"
  },
  {
    "id": 2,
    "title": "Authentication and API Key Setup: Secure your API integrations with AIKosh",
    "description": "Authentication ensures only trusted users access AIKosh APIs. With API keys, each request is verified, keeping your data safe and integrations secure from unauthorized access.",
    "image_url": null,
    "overview": "Authentication is a foundational requirement when exposing or consuming data through AIKosh APIs. Every API request must prove the identity of the caller and verify whether they are authorized to access a given resource. By using API keys and secure authentication practices, AIKosh ensures that only verified contributors can expose data, dataset access remains restricted to approved scopes, and the overall platform stays secure, traceable, and trustworthy.",
    "key_capabilities": "Secure API Authentication: Ensures every API request is authenticated using a valid API key.\nAuthorization Control: Restricts access to datasets and resources based on approved scopes.\nStandardized Header Usage: Uses the Authorization: Bearer <API_KEY> header across all secured endpoints.\nMulti-endpoint Protection: Applies authentication uniformly to metadata, preview, listing, and download APIs.\nDeveloper-Friendly Examples: Provides clear cURL and Python examples for quick integration.\nOperational Security Guidance: Includes best practices for storage, rotation, and usage of API keys.",
    "why_it_is_included": "This toolkit is included to help contributors and developers securely integrate with AIKosh APIs. It establishes a clear understanding of why authentication matters, how API keys function, and how to correctly use them across different endpoints. By following these practices, users can build secure, compliant, and reliable programmatic pipelines while protecting sensitive data and platform integrity.",
    "resources_on_getting_started": "API Header Format: Authorization: Bearer YOUR_API_KEY\nExample Endpoints:\n- /api/datasets/metadata\n- /api/datasets/preview\n- /api/datasets/download\n- /api/datasets/list\ncURL Example and Python requests example provided for quick testing and integration.\nAPI Key Generation via Contributor Dashboard under API Access.",
    "license_and_compliance": "API access and authentication practices comply with AIKosh platform security standards. Secure usage is enforced through HTTPS (TLS 1.2+) and recommended best practices such as secret storage, key rotation, and restricted permissions to ensure compliance with data security requirements.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 3,
    "title": "Fetch File Download URL – Enable Secure Dataset File Delivery",
    "description": "The Fetch File Download URL API gives secure, short-lived links to download datasets, helping you share files safely without using static links. It keeps your data delivery secure, scalable, and trackable.",
    "image_url": null,
    "overview": "Once users inspect a dataset and decide it is useful, they need a secure way to download the full file. The Fetch File Download URL API enables programmatic generation of short-lived, secure download links for specific dataset files. Instead of exposing static URLs, this API dynamically returns tokenized or signed URLs, ensuring secure, scalable, and auditable data delivery.",
    "key_capabilities": "Secure Download URL Generation: Produces short-lived, tokenized download links for dataset files.\nTime-bound Access Control: Supports expiration windows (typically 5–15 minutes) to reduce misuse.\nFile-level Access: Generates URLs for specific files using datasetIdentifier and fileIdentifier.\nScalable Delivery: Works with cloud storage (e.g., pre-signed S3 URLs), CDNs, or secure local proxies.\nAuditability: Enables tracking and logging of file download requests.\nSeparation of Concerns: Cleanly separates metadata access from actual data delivery.",
    "why_it_is_included": "This toolkit is included to ensure secure and controlled dataset file delivery on AIKosh. By avoiding static links and enforcing short-lived, authenticated download URLs, it protects sensitive data, supports scalable infrastructure, and provides an auditable mechanism for managing dataset downloads in production integrations.",
    "resources_on_getting_started": "Endpoint: GET /api/datasets/download?datasetIdentifier=<ID>&fileIdentifier=<FILE_ID>\nRequired Header: Authorization: Bearer YOUR_API_KEY\nSupports cloud pre-signed URLs or JWT/token-secured self-hosted links.\nUse Postman or cURL examples to validate link generation and expiration behavior.",
    "license_and_compliance": "API usage follows AIKosh security standards. All requests must use HTTPS with TLS 1.2 or higher. Download URLs must be signed or tokenized, time-limited, and must not expose internal storage paths or bucket details to comply with secure data access practices.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 4,
    "title": "Fetch Dataset List: Programmatically retrieve all Datasets by Organisation",
    "description": "The Fetch Dataset List API helps platforms get a quick list of all datasets, useful for integration, API key checks, and managing multiple datasets easily.",
    "image_url": null,
    "overview": "For platforms and contributors that manage multiple datasets, it is essential to have a lightweight API to retrieve a list of all available datasets. The Fetch Dataset List API provides a simple and efficient way to programmatically fetch dataset identifiers and names associated with an authenticated organization. This endpoint is particularly useful for auto-fetching dataset identifiers for integration workflows and validating API key access scope with organization-level isolation.",
    "key_capabilities": "Organization-level Dataset Listing: Returns only datasets associated with the authenticated organization.\nLightweight Response: Provides minimal but essential dataset information such as identifier and name.\nIntegration Friendly: Acts as the first API call in automated workflows, CLI tools, and platform integrations.\nScope Validation: Helps verify API key permissions and organization isolation.\nStructured Responses: Clearly defined success and failure JSON responses for easy parsing.",
    "why_it_is_included": "This toolkit is included to enable contributors and platforms to efficiently manage multiple datasets programmatically. By offering a simple and secure way to list datasets, it forms the foundation for downstream operations such as metadata retrieval, preview access, and dataset downloads while maintaining strict organization-level data isolation.",
    "resources_on_getting_started": "Endpoint: GET /api/datasets/list\nRequired Header: Authorization: Bearer YOUR_API_KEY\nSample cURL and Postman configurations provided for quick testing.\nUse returned dataset identifiers to call metadata, preview, and download APIs.",
    "license_and_compliance": "Access to this API follows AIKosh platform security policies. All requests must use HTTPS with TLS 1.2 or higher. API keys define organization context and must be kept secure to ensure compliance with data access and security requirements.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 5,
    "title": "Fetch Dataset Preview – Deliver Data Snapshots via API",
    "description": "The Fetch Dataset Preview API shows a quick sample of data, helping users check format and relevance before downloading.",
    "image_url": null,
    "overview": "Before downloading a full dataset, consumers often need a quick way to inspect its structure and sample content. The Fetch Dataset Preview API enables this by returning a limited number of rows from a specified dataset file. This allows users to validate formatting, understand column structure, and confirm relevance without transferring the entire file, improving trust and usability.",
    "key_capabilities": "Row-level Data Preview: Returns a small, configurable number of sample rows from a dataset file.\nFormat Validation: Helps users understand column layout, data types, and encoding before download.\nEarly Issue Detection: Allows quick identification of nulls, malformed rows, or obvious data quality issues.\nUI-friendly Output: Provides JSON-formatted previews suitable for rendering tables in user interfaces.\nControlled Access: Ensures previews are only available for public or authorized datasets.",
    "why_it_is_included": "This toolkit is included to improve dataset transparency and user confidence on AIKosh. By allowing users to preview data before downloading, it reduces unnecessary data transfers, improves decision-making, and ensures datasets meet user expectations while maintaining secure and controlled access.",
    "resources_on_getting_started": "Endpoint: POST /api/datasets/preview\nRequired Headers: Authorization: Bearer YOUR_API_KEY, Content-Type: application/json\nRequest Body Parameters: datasetIdentifier, fileIdentifier, noOfRowsInPreview\nUse Postman or cURL examples to test preview responses and row limits.",
    "license_and_compliance": "The API follows AIKosh security and access control policies. All requests must use HTTPS with TLS 1.2 or higher. Dataset previews must respect authorization rules and avoid exposing sensitive or personally identifiable information (PII).",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 6,
    "title": "Fetch Dataset Metadata – Enable Seamless Dataset Discovery via API",
    "description": "Lets contributors share machine-readable dataset summaries, making them discoverable and usable without downloads. This toolkit covers the API purpose, structure, implementation, and best practices.",
    "image_url": null,
    "overview": "When organizations contribute datasets to AIKosh, exposing a machine-readable summary is essential for discoverability and interoperability. The Fetch Dataset Metadata API provides descriptive metadata for datasets, enabling consumers to explore dataset details without downloading files. This supports dataset cards, filtering, and metadata-driven search across the platform.",
    "key_capabilities": "Comprehensive Metadata Retrieval: Returns dataset name, descriptions, license, visibility, and ownership details.\nFile-level Details: Includes file format, size, row and column counts, and file identifiers.\nColumn-level Statistics: Provides schema information such as data types, null counts, distinct values, and basic statistics.\nDiscovery Enablement: Powers dataset cards, filters, and search without requiring data downloads.\nSecure Access: Enforces authenticated access via Bearer tokens over HTTPS.",
    "why_it_is_included": "This toolkit is included to standardize how datasets are documented and discovered on AIKosh. By exposing rich, structured metadata, contributors make datasets easier to understand, compare, and trust, while consumers can evaluate relevance and quality before accessing the actual data.",
    "resources_on_getting_started": "Endpoint: GET /api/datasets/metadata?datasetIdentifier=<ID>\nRequired Header: Authorization: Bearer YOUR_API_KEY\nResponse should include dataset-level, file-level, and column-level metadata.\nUse Postman or cURL to validate responses against the sample JSON structure.",
    "license_and_compliance": "All requests must use HTTPS with TLS 1.2 or higher. Access is controlled via API keys, which should be securely stored, rotated regularly, and scoped to read-only access for metadata endpoints to comply with platform security standards.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 7,
    "title": "DataCleaner",
    "description": "Minimalist, command-line tool for basic data cleaning operations on CSV files — ideal for scripting and batch use.",
    "image_url": null,
    "overview": "DataCleaner is a lightweight command-line utility designed for quick data cleaning, transformation, and preprocessing of structured files like CSVs. It is optimized for shell-based workflows, enabling fast rule-based operations without requiring a full programming setup. With support for imputation, type conversion, standardization, and format correction, it is well-suited for remote servers, pipelines, and low-resource environments. Its scriptable nature allows repeatable and auditable data preparation before downstream tasks such as annotation or analysis.",
    "key_capabilities": "Command-Line Interface (CLI): Runs directly from the terminal with no GUI or heavy dependencies.\nBatch File Support: Processes single or multiple CSV files via scripted commands.\nRule-Based Cleaning: Supports standard operations such as dropping nulls, fixing types, and standardizing formats.\nType Inference & Conversion: Automatically detects data types and allows corrections (e.g., string to integer).\nMissing Value Handling: Options to delete, fill, or flag null or missing values.\nColumn Normalization: Lowercases headers, trims whitespace, and renames columns.\nAudit Logging: Logs every operation in a changelog for transparency and traceability.",
    "why_it_is_included": "DataCleaner is included to support contributors who need a fast, no-dependency approach to dataset cleaning, especially in bash-first workflows, remote VMs, or low-resource systems. It complements heavier tools by focusing on quick, automatable pre-cleaning and is ideal for preparing datasets before bulk uploads or processing with more complex tools.",
    "resources_on_getting_started": "Official Link: https://datacleaner.github.io/\nDocumentation: https://datacleaner.github.io/documentation\nGitHub: https://github.com/datacleaner/DataCleaner\nInstallation: pip install datacleaner-cli\nSample Usage:\n- datacleaner clean --input data.csv --output cleaned.csv\n- datacleaner clean --input records.csv --output clean_records.csv --log logs/clean_log.txt\n- datacleaner batch --input-folder raw_data/ --output-folder cleaned_data/\nConfig-based Cleaning supported via YAML (e.g., cleaning_rules.yml).",
    "license_and_compliance": "License: MIT License. DataCleaner is fully open-source, modifiable, and compliant with AIKosh policies. It can be used, adapted, and redistributed without legal restrictions.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v1.3.2 (as of February 2025)\nGitHub Stars: 500+\nActive Contributors: 10+\nLast Updated: February 2025"
  },
  {
    "id": 8,
    "title": "DataPrep",
    "description": "Lightweight Python library for data cleaning, profiling, and exploratory analysis, ideal for quick data preparation tasks.",
    "image_url": null,
    "overview": "DataPrep is an open-source Python library that simplifies exploring, cleaning, and preparing datasets for analysis and machine learning. It provides intuitive functions for profiling datasets, cleaning inconsistent fields such as emails and phone numbers, and visualizing distributions with minimal code. Designed to integrate seamlessly with pandas and Jupyter notebooks, DataPrep helps users quickly validate, understand, and prepare structured datasets like CSVs or database exports.",
    "key_capabilities": "Data Profiling (Exploration): Generates summaries with missing value reports, type detection, and distribution plots.\nData Cleaning: Built-in cleaners for phone numbers, emails, URLs, dates, and currencies with automated handling of invalid formats.\nExploratory Data Analysis (EDA): Visualizations including correlation matrices, missing value heatmaps, and histograms.\nSeamless Integration: Works directly with pandas DataFrames and Jupyter notebooks.\nLow-Code & Scriptable: Performs thorough analysis and cleaning with minimal lines of code.\nOptional Streamlit Dashboard: Launches an interactive, browser-based EDA UI without writing code.",
    "why_it_is_included": "DataPrep is included to help AIKosh contributors quickly explore, clean, and validate structured datasets before submission. It lowers the barrier for beginners while remaining powerful for experienced users, fitting naturally into Python-centric data science workflows and serving as a lightweight alternative to heavier tools or manual spreadsheet work.",
    "resources_on_getting_started": "GitHub: https://github.com/sfu-db/dataprep\nColab Example: https://colab.research.google.com/drive/1U_-pAMcne3hK1HbMB3kuEt-093Np_7Uk?usp=sharing\nInstallation: pip install dataprep\nQuick Start (Jupyter): create_report(df)\nStandard Usage examples for cleaning countries, phones, and emails included.\nOptional Streamlit EDA dashboard available (requires separate streamlit installation).",
    "license_and_compliance": "License: Apache License 2.0. DataPrep is open-source, self-hostable, modifiable, and permitted for commercial and non-commercial use, aligning with AIKosh open-source contribution guidelines.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v0.4.3 (as of February 2025)\nGitHub Stars: 2k+\nActive Contributors: 40+\nLast Updated: February 2025"
  },
  {
    "id": 9,
    "title": "Shoonya",
    "description": "Open-source platform for multilingual text and speech annotation, designed specifically for Indian language datasets.",
    "image_url": null,
    "overview": "Shoonya, developed by AI4Bharat, is an open-source data annotation platform tailored for Indian languages. It supports text annotation, speech transcription, translation, and quality verification across multiple Indic scripts and audio formats. With a user-friendly web interface and built-in workforce management, Shoonya enables collaborative, structured, and consistent dataset creation for NLP, ASR, and machine translation projects focused on Indian languages.",
    "key_capabilities": "Multilingual Support: Annotation support for 20+ Indian languages including Hindi, Tamil, Telugu, Marathi, Bengali, and more.\nModality Support: Handles both text and audio data.\nAnnotation Types: Text translation, speech transcription, speech translation, and verification workflows.\nWorkforce Management: Role-based access, team assignments, and progress tracking.\nProject Templates: Predefined task types for rapid project setup.\nSelf-Hosting Ready: Deployable using Docker Compose for scalable environments.\nMetrics and Analytics: Real-time monitoring of task progress and workload distribution.",
    "why_it_is_included": "Shoonya is included in AIKosh because it directly addresses the need for high-quality annotation of multilingual, low-resource Indian languages. Its specialization in Indic text and speech, combined with workforce management and open-source flexibility, makes it highly valuable for public sector, academic, and research-driven dataset creation in Indian contexts.",
    "resources_on_getting_started": "Official Website: https://shoonya.ai4bharat.org/\nGitHub Repository: https://github.com/AI4Bharat/shoonya\nDocumentation: https://github.com/AI4Bharat/Shoonya/wiki\nInstallation (Recommended): Docker Compose\nCommands:\n- git clone https://github.com/AI4Bharat/shoonya.git\n- cd shoonya\n- docker-compose up -d\nDefault access URL: http://localhost:3000\nRequires PostgreSQL, Django backend, and React frontend (managed via Docker).",
    "license_and_compliance": "License: Apache License 2.0. Shoonya complies with AIKosh open-source contribution standards and can be freely hosted, customized, and modified for commercial or non-commercial use.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v1.2.0 (as of March 2025)\nGitHub Stars: 300+\nActive Contributors: 20+\nLast Updated: March 2025"
  },
  {
    "id": 10,
    "title": "Label Studio",
    "description": "Flexible, open-source data labeling tool for annotating text, images, audio, video, and tabular data through a highly customizable web interface.",
    "image_url": null,
    "overview": "Label Studio is a versatile open-source data annotation platform supporting a wide range of data types including text, images, audio, video, HTML, and tabular formats. It enables manual and model-assisted labeling through a customizable web-based interface. Users can define labeling configurations using YAML, export annotations in multiple standard formats, and extend functionality via plugins and APIs. It is suitable for individuals, teams, and enterprises building training datasets for machine learning, NLP, computer vision, and audio processing.",
    "key_capabilities": "Multi-Modality Support: Annotation for text, images, audio, video, HTML, time series, and tabular data.\nFlexible Labeling Interface: Customizable UIs using simple YAML configuration files.\nPre-Labeling & Model-Assisted Labeling: Integrates ML models to accelerate annotation.\nAPI Access: Comprehensive REST API for programmatic task and result management.\nVersioning & Collaboration: Role-based access control, project versioning, and team collaboration.\nDeployment Flexibility: Runs locally, on-premises, or in the cloud (AWS, GCP, Azure compatible).\nExport Formats: Supports JSON, CSV, COCO, YOLO, Pascal VOC, and more.\nPlugin System: Extend features with community or custom plugins.",
    "why_it_is_included": "Label Studio is included in AIKosh for its flexibility, extensibility, and robust API support across diverse annotation use cases. Its open-source, self-hosted model aligns with secure and scalable dataset creation needs for researchers, ML practitioners, and government contributors, enabling efficient production of high-quality labeled data.",
    "resources_on_getting_started": "Official Website: https://labelstud.io/\nGitHub Repository: https://github.com/heartexlabs/label-studio\nDocumentation: https://labelstud.io/guide/\nAPI Docs: https://labelstud.io/api/\nDocker Hub: https://hub.docker.com/r/heartexlabs/label-studio\nVideo Tutorials: https://labelstud.io/videos/\nQuick Start:\n- pip install label-studio\n- label-studio start\nDocker (Production):\n- docker pull heartexlabs/label-studio:latest\n- docker run -it -p 8080:8080 heartexlabs/label-studio:latest\nDefault URL: http://localhost:8080",
    "license_and_compliance": "License: Apache License 2.0. Label Studio is fully open-source, self-hostable, and modification-friendly, compliant with AIKosh policies for commercial and non-commercial use.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v1.11.0 (as of April 2025)\nGitHub Stars: 13k+\nActive Contributors: 250+\nLast Updated: March 2025"
  },
  {
    "id": 11,
    "title": "Presidio",
    "description": "Enterprise-grade open-source tool for detecting and anonymizing sensitive personal information (PII) in text and structured data.",
    "image_url": null,
    "overview": "Presidio is an enterprise-grade open-source framework developed to detect and anonymize sensitive personal information (PII) in unstructured text and semi-structured data. It uses NLP-based techniques combined with rule-based and custom recognizers to accurately identify sensitive entities such as names, emails, phone numbers, credit card details, and IP addresses. Presidio is designed for privacy-first data pipelines and supports scalable deployments for production environments.",
    "key_capabilities": "PII Detection and Anonymization: Detects and anonymizes 20+ PII entity types including names, addresses, emails, phone numbers, credit card numbers, and IP addresses.\nMulti-Language Support: Configurable primarily for English, with extensibility for additional languages.\nCustom Recognizers: Allows users to define custom PII detectors using regex, ML models, or hybrid approaches.\nModular Architecture: presidio-analyzer for detection and presidio-anonymizer for redaction, masking, replacement, or encryption.\nFlexible Deployment: Available as Python libraries, REST APIs via Docker, and Kubernetes-ready services.\nPrebuilt Docker Images: Ready-to-use containers for analyzer and anonymizer services.\nAuditability: Provides transparent logging for detection and anonymization operations.",
    "why_it_is_included": "Presidio is included in AIKosh to enable contributors to anonymize sensitive information reliably before dataset contribution. Its NLP-driven approach offers higher accuracy than simple regex-based tools, especially for unstructured text such as emails, chat logs, and documents. It aligns strongly with AIKosh’s data governance, privacy protection, and open-source compliance requirements.",
    "resources_on_getting_started": "Official Website: https://microsoft.github.io/presidio/\nGitHub Repository: https://github.com/microsoft/presidio\nDemo: https://huggingface.co/spaces/presidio/presidio_demo\nDocumentation: https://microsoft.github.io/presidio/installation/\nAPI Docs: https://microsoft.github.io/presidio/analyzer/api/\nDocker Images: mcr.microsoft.com/presidio/presidio-analyzer, mcr.microsoft.com/presidio/presidio-anonymizer\nInstall via pip: pip install presidio-analyzer presidio-anonymizer\nDefault Ports: Analyzer (3000), Anonymizer (3001)",
    "license_and_compliance": "License: MIT License. Presidio is fully open-source and compliant with AIKosh policies, allowing self-hosting, modification, and use in both commercial and non-commercial environments.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v2.2.1 (as of March 2025)\nGitHub Stars: 2.7k+\nActive Contributors: 30+\nLast Updated: February 2025"
  },
  {
    "id": 12,
    "title": "Doccano",
    "description": "Lightweight and intuitive annotation tool for NLP tasks like text classification, named entity recognition, and sequence-to-sequence labeling.",
    "image_url": null,
    "overview": "Doccano is an open-source, web-based annotation tool designed specifically for Natural Language Processing (NLP) tasks. It supports sequence labeling (NER), text classification (such as sentiment and topic classification), and sequence-to-sequence tasks including translation and summarization. With a simple collaborative interface, role-based access control, and support for common data formats, Doccano is well-suited for small teams, research projects, and contributors working with text-heavy datasets.",
    "key_capabilities": "Annotation Task Support: Text classification, Named Entity Recognition (NER), and sequence-to-sequence tasks (translation, summarization).\nData Format Compatibility: Supports CSV, JSON, JSONL, and plain text inputs.\nMulti-User Collaboration: Role-based access control for admins, annotators, and approvers.\nEasy Setup & Deployment: Minimal dependencies with installation via pip or Docker.\nBuilt-In Labeling UI: Enables tagging of text spans, tokens, or entire documents.\nExport Options: Export annotations in multiple formats suitable for ML model training.",
    "why_it_is_included": "Doccano is included to provide a simple yet effective solution for text annotation without complex infrastructure. It is particularly valuable for AIKosh contributors handling surveys, social media data, transcripts, and other NLP-focused datasets. Its focused support for NER, classification, and translation tasks makes it an excellent choice for smaller teams and academic or research-driven projects.",
    "resources_on_getting_started": "Official Website: https://doccano.github.io/doccano/\nGitHub Repository: https://github.com/doccano/doccano\nDocker Deployment (Recommended):\n- git clone https://github.com/doccano/doccano.git\n- cd doccano\n- docker-compose -f docker-compose.dev.yml up\nAccess URL: http://localhost:8000\nCreate Admin:\n- doccano init\n- doccano createuser --username admin --password admin --email admin@example.com\nInstall via pip:\n- pip install 'doccano[postgresql]' (or 'sqlite' for lightweight setup)",
    "license_and_compliance": "License: MIT License. Doccano is fully open-source and compliant with AIKosh policies. It can be customized and used for both public and private annotation workflows.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v1.10.1 (as of April 2025)\nGitHub Stars: 8.4k+\nActive Contributors: 100+\nLast Updated: March 2025"
  },
  {
    "id": 13,
    "title": "OCR Toolkit",
    "description": "OCR utility for extracting printed or handwritten text from images, scans, and PDFs.",
    "image_url": null,
    "overview": "The OCR Toolkit in AIKosh provides a unified interface for extracting textual data from visual documents such as scanned forms, handwritten notes, typed reports, and photographic inputs. It converts unstructured image-based data into machine-readable text for downstream tasks like anonymization, cleaning, annotation, or translation. The module currently uses the open-source Tesseract OCR engine, supporting over 100 languages, and is designed to be extensible for future enhancements such as engine selection and model fine-tuning via UI controls.",
    "key_capabilities": "Multi-format Input Support: Works with images (JPG, PNG), PDFs, and scanned documents.\nMultilingual Recognition: Supports many languages, including Indian languages and right-to-left scripts.\nHandwritten and Printed Text OCR: Handles typed, printed, and moderately clear handwritten content.\nIntegrated Preprocessing: Includes noise reduction, binarization, and contrast enhancement for better accuracy.\nOffline Execution: Runs fully locally without requiring internet connectivity.\nEngine Extensibility: Designed to support additional OCR engines and configurations.\nSearchable PDF Output: Generates searchable PDFs from scanned documents.",
    "why_it_is_included": "The OCR Toolkit is included to bridge the gap between physical and digital data workflows for AIKosh contributors. It enables text extraction from non-digital sources such as historical documents, physical records, and mobile-captured field data, making them accessible for further processing. By using a stable open-source OCR engine with a simple interface, it delivers reliable results with minimal operational overhead while supporting language inclusivity.",
    "resources_on_getting_started": "Typical Flow: Upload image or scanned file, select language/script, run OCR, and export text or searchable PDF.\nBackend Engine: https://github.com/tesseract-ocr/tesseract\nPython Wrapper: https://github.com/madmaze/pytesseract\nDocumentation: https://tesseract-ocr.github.io/tessdoc/\nPython Example (pytesseract): from PIL import Image; import pytesseract; image = Image.open('sample_scan.png'); text = pytesseract.image_to_string(image, lang='eng')",
    "license_and_compliance": "License: Apache License 2.0. The OCR Toolkit is fully open-source and compliant with AIKosh tooling policies. All processing is local, modifiable, and suitable for integration into secure workflows.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Core Engine Version (Tesseract): v5.4.0 (as of March 2025)\nGitHub Stars: 53k+\nActive Contributors: 500+\nLast Updated: March 2025"
  },
  {
    "id": 14,
    "title": "Data Anonymization Toolkit",
    "description": "In-house, web-based anonymization tool designed specifically for structured CSV data, offering an accessible GUI and advanced privacy-preserving techniques tailored for government and public datasets.",
    "image_url": null,
    "overview": "The AIKosh Data Anonymization Toolkit is an in-house utility built to simplify and standardize the anonymization of structured datasets prior to contribution. Optimized for CSV files, it provides a web-based interface for uploading, processing, previewing, and exporting anonymized data. The tool combines automatic detection of sensitive fields with configurable transformation methods, enabling both technical and non-technical users to achieve privacy compliance efficiently. Its workflow-centric design supports end-to-end anonymization, making it well-suited for public sector and government datasets.",
    "key_capabilities": "File Upload Interface: Drag-and-drop browser-based upload of CSV datasets.\nAuto Detection: Identifies PII fields such as names, phone numbers, emails, and identifiers using heuristics and regex.\nMultiple Anonymization Techniques: Masking, hashing (SHA256), generalization, pseudonymization, perturbation, suppression, partial encryption, swapping, and blurring.\nSide-by-Side Preview Mode: Displays original and anonymized records simultaneously for validation.\nCSV Export: Download fully anonymized datasets after review.\nREST API Layer: Supports automated and large-scale anonymization workflows programmatically.",
    "why_it_is_included": "This toolkit is included to enable contributors—especially from government and public domains—to anonymize structured data without requiring programming expertise. Tailored specifically for CSV formats common in official records, it offers field-level transformations through an intuitive GUI while adhering to standard privacy practices. Its usability, robustness, and privacy-first design make it essential for preparing high-sensitivity datasets for sharing or publication.",
    "resources_on_getting_started": "Access: Internal AIKosh Web Portal (contact platform admin).\nTypical Workflow: Upload CSV, review detected sensitive fields, choose anonymization techniques, preview results side-by-side, export anonymized CSV or integrate via REST APIs.",
    "license_and_compliance": "License: Apache License 2.0. The toolkit is fully compliant with AIKosh privacy policies and government data protection standards, suitable for internal sharing and approved public data releases.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 15,
    "title": "Hallucination – Responsible AI Toolkit",
    "description": "Module for detecting and reducing hallucinated LLM content, using reasoning traces and accuracy checks to ensure factual, reliable, and grounded AI responses.",
    "image_url": null,
    "overview": "The Hallucination module in the Infosys Responsible AI Toolkit is designed to detect, quantify, and mitigate hallucinated content in large language model (LLM) outputs. It applies advanced reasoning and verification techniques such as Chain of Thought, Thread of Thought, Graph of Thought, and Chain of Verification to trace reasoning paths and validate factual accuracy. By combining Retrieval-Augmented Generation (RAG) across documents, images, audio, and video with G-Eval metrics, the module ensures AI-generated responses are grounded, verifiable, and trustworthy.",
    "key_capabilities": "Document RAG: Extracts and verifies information from documents to reduce hallucinations.\nImage RAG: Incorporates image-based context through multimodal retrieval-augmented generation.\nVideo/Audio RAG: Enhances understanding of video and audio content using retrieval-based grounding.\nHallucination Score: Quantifies the likelihood of fabricated or inaccurate content in LLM responses.\nG-Eval Metrics: Evaluates relevance, adherence, correctness, and faithfulness with interpretable scores.\nChain of Thoughts (CoT): Breaks down complex reasoning into logical steps.\nThread of Thoughts (ToT): Prioritizes relevant information in complex or noisy contexts.\nLogic of Thoughts (LoT): Augments prompts with structured logical information for improved reasoning.\nChain of Verification: Performs multi-step factual validation of LLM responses.",
    "why_it_is_included": "This toolkit is included in AIKosh to address a critical challenge in deploying LLMs: hallucinations that produce plausible but incorrect information. By detecting, scoring, and mitigating hallucinations through advanced reasoning, verification, and RAG techniques, the module improves factual accuracy and trustworthiness. It aligns with AIKosh’s mission to promote safe, transparent, and responsible AI systems suitable for real-world and public-sector use.",
    "resources_on_getting_started": "GitHub Repository: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-Hallucination\nCompatible Models: Azure OpenAI (gpt-4o-mini), Google Gemini (gemini-2.0-flash, gemini-2.5-flash-preview-04-17, gemini-2.5-pro-preview-03-25), AWS Bedrock (claude-3-sonnet)\nFollow repository documentation for setup, configuration, and example workflows.",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible. It supports both commercial and non-commercial use and aligns with AIKosh principles for transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 16,
    "title": "Computer Vision Annotation Toolkit",
    "description": "Open-source, web-based tool for annotating images and videos, supporting a wide range of computer vision tasks.",
    "image_url": null,
    "overview": "CVAT (Computer Vision Annotation Tool) is a versatile open-source platform developed by Intel for annotating visual data. It supports multiple annotation types such as bounding boxes, polygons, polylines, points, and cuboids, making it suitable for tasks like object detection, image classification, and image segmentation. CVAT offers both manual and semi-automatic annotation capabilities, integrates with deep learning models to speed up labeling, and provides a collaborative web-based interface for team workflows.",
    "key_capabilities": "Annotation Types: Bounding boxes, polygons, polylines, points, and cuboids.\nSemi-Automatic Annotation: Integration with deep learning models to assist and accelerate labeling.\nVideo Annotation Support: Interpolation of shapes between keyframes for efficient video labeling.\nCollaborative Interface: Role-based access control enabling team collaboration.\nFormat Support: Import and export in common formats such as COCO, Pascal VOC, and YOLO.\nExtensibility: Plugin architecture for adding custom functionality.",
    "why_it_is_included": "CVAT is included in AIKosh’s utility repository because it provides robust, production-grade tooling for annotating image and video datasets. Its wide annotation support, collaboration features, and open-source flexibility make it especially valuable for contributors building high-quality computer vision datasets for machine learning applications.",
    "resources_on_getting_started": "Official Website: https://www.cvat.ai/\nGitHub Repository: https://github.com/opencv/cvat\nDocumentation: https://docs.cvat.ai/docs/",
    "license_and_compliance": "License: MIT License. CVAT is fully open-source and compliant with AIKosh’s policy of preferring freely available and modifiable tools.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v2.3.0 (as of April 2025)\nGitHub Stars: 7.5k+\nActive Contributors: 200+\nLast Updated: March 2025"
  },
  {
    "id": 17,
    "title": "Fairness & Bias – Responsible AI Toolkit",
    "description": "Toolkit feature for detecting bias in ML models, LLMs, and images, offering fairness checks across diverse groups to support inclusive, balanced, and responsible AI outcomes.",
    "image_url": null,
    "overview": "Fairness and Bias is a core tenet of the Infosys Responsible AI Toolkit that enables comprehensive evaluation of AI systems for potential bias. It supports analysis of traditional machine learning models, large language models (LLMs), and image-based AI systems. The toolkit evaluates fairness across demographic, socio-economic, cultural, and geographic dimensions, helping organizations identify biased patterns in training data, model predictions, and generated content. By combining structured data analysis with LLM-powered evaluations, it promotes transparent and inclusive AI deployment.",
    "key_capabilities": "Structured Data Bias Analysis: Detects bias in structured datasets using ground truth labels or model predictions.\nBias Mitigation Support: Enables mitigation of bias during the pre-training phase of traditional ML models.\nIndividual Fairness Metrics: Evaluates fairness at the individual level, not just across groups.\nLLM Bias Detection: Analyzes generated text for biased content, affected groups, and bias categories using LLMs such as GPT, Gemini, and Claude.\nImage Bias Detection: Identifies bias and stereotypes in uploaded images to support inclusive vision systems.",
    "why_it_is_included": "This toolkit is included in AIKosh to ensure AI systems deliver equitable and inclusive outcomes. By detecting and mitigating bias across structured data, unstructured text, and images, it helps organizations build AI solutions that are transparent, fair, and socially responsible. It aligns strongly with AIKosh’s commitment to ethical AI development and responsible deployment at scale.",
    "resources_on_getting_started": "GitHub Repository: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-fairness\nSetup Notes: Ensure setup.py version is correct, --universal flag is optional, and update requirements.txt with the correct .whl filename as required by the toolkit.",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 18,
    "title": "Chitralekha",
    "description": "Open-source platform for video transcreation across various Indic languages, supporting transcription, translation, and voice-over.",
    "image_url": null,
    "overview": "Chitralekha, developed by AI4Bharat, is an open-source platform designed for the transcreation of video content in Indic languages. It integrates Automatic Speech Recognition (ASR), Neural Machine Translation (NMT), and Text-to-Speech (TTS) models to enable transcription, translation, and voice-over generation. Supporting inputs from YouTube and local files, Chitralekha provides end-to-end tooling for editing and exporting subtitles and audio, making it a comprehensive solution for localizing video content across India’s diverse linguistic landscape.",
    "key_capabilities": "Input Sources: Supports video import from YouTube links and local files.\nTranscription: Generates accurate, timestamped transcriptions using ASR models.\nTranslation: Translates transcripts into multiple Indic languages via NMT models.\nVoice-over Generation: Produces voice-overs for translated subtitles using TTS models.\nEditing Tools: Allows manual refinement of transcriptions, translations, and voice-overs.\nExport Options: Exports subtitles and voice-over audio in standard formats for distribution.",
    "why_it_is_included": "Chitralekha is included in AIKosh because it uniquely addresses the need for multilingual video localization in Indic languages. By combining ASR, NMT, and TTS in a single open-source platform, it enables contributors to efficiently transcreate video content, improving accessibility and reach of information across different regions and language communities in India.",
    "resources_on_getting_started": "Official Website: https://chitralekha.ai4bharat.org/\nGitHub Repository: https://github.com/AI4Bharat/Chitralekha\nDocumentation: https://github.com/AI4Bharat/Chitralekha/blob/master/README.md",
    "license_and_compliance": "License: MIT License. Chitralekha is fully open-source and compliant with AIKosh policies, allowing free modification, redistribution, and use for both commercial and non-commercial purposes.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v1.0.0 (as of March 2025)\nGitHub Stars: 500+\nActive Contributors: 30+\nLast Updated: March 2025"
  },
  {
    "id": 19,
    "title": "iNLTK",
    "description": "Toolkit providing out-of-the-box support for various NLP tasks in Indic languages.",
    "image_url": null,
    "overview": "iNLTK (Indic Natural Language Toolkit) is a Python library that provides pre-trained language models and easy-to-use APIs for performing common NLP tasks in Indic languages. It supports tokenization, sentence similarity, text generation, language identification, and embeddings across a wide range of Indian languages. By abstracting complex model usage behind simple interfaces, iNLTK makes it easier for developers and researchers to build NLP applications tailored to Indian language data.",
    "key_capabilities": "Supported Languages: Hindi, Punjabi, Sanskrit, Gujarati, Kannada, Malayalam, Nepali, Odia, Marathi, Bengali, Tamil, and Urdu.\nTokenization: Language-specific tokenization optimized for Indic scripts.\nSentence Similarity: Computes similarity scores between sentences.\nText Generation: Generates text from input prompts using pre-trained models.\nLanguage Identification: Automatically detects the language of input text.\nEmbeddings: Provides sentence-level and word-level embeddings for downstream tasks.",
    "why_it_is_included": "iNLTK is included in AIKosh’s utility repository because it significantly lowers the barrier to working with Indic language text. Its pre-trained models and simple APIs enable developers to quickly build inclusive NLP applications for Indian languages, supporting AIKosh’s goal of language diversity and accessibility in AI systems.",
    "resources_on_getting_started": "Documentation: https://inltk.readthedocs.io/en/latest/\nGitHub Repository: https://github.com/goru001/inltk",
    "license_and_compliance": "License: MIT License. iNLTK is fully open-source and compliant with AIKosh policies, allowing free modification and use for both commercial and non-commercial purposes.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": "Latest Release Version: v0.9 (as of March 2025)\nGitHub Stars: 800+\nActive Contributors: 5+\nLast Updated: March 2023"
  },
  {
    "id": 20,
    "title": "Foundation Model Moderation Layer – Responsible AI Toolkit",
    "description": "Moderation module for managing AI inputs and outputs, offering real-time safety, fairness, and compliance checks across traditional and generative models.",
    "image_url": null,
    "overview": "The Foundation Model (FM) Moderation Layer is a core component of the Infosys Responsible AI Toolkit, designed to safeguard AI systems by moderating inputs and outputs for safety, security, privacy, and fairness. It provides a modular set of APIs that integrate with both traditional machine learning models and modern generative AI systems. The layer includes request moderation, response moderation, and response comparison, enabling real-time risk detection, explanation, and compliance monitoring aligned with ethical, legal, and organizational standards.",
    "key_capabilities": "Model-based Guardrails: Uses traditional AI models to detect prompt injection, jailbreak attempts, toxicity, and other risks.\nTemplate-based Guardrails: Applies reusable prompt templates for consistent moderation across LLMs.\nTranslate Option: Translates non-English prompts into English to improve protection against multilingual jailbreak attacks.\nMultimodal Moderation: Supports moderation of both text and image inputs using multimodal model capabilities.\nResponse Comparison: Compares raw LLM outputs with moderated outputs to highlight the impact of applied guardrails.\nMultiple LLM Support: Compatible with models such as GPT-4 Turbo, Claude, Gemini, and LLaMA 3.",
    "why_it_is_included": "The FM Moderation Layer is included in AIKosh to provide a critical protection layer for AI deployments. By proactively identifying and mitigating risks related to safety, security, privacy, and fairness, it ensures responsible use of both traditional and generative AI models. Its modular design, multilingual and multimodal support, and broad model compatibility align strongly with AIKosh’s mission to promote secure, ethical, and trustworthy AI systems at scale.",
    "resources_on_getting_started": "GitHub Repository (Moderation Layer): https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-moderationlayer\nGitHub Repository (Moderation Models): https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-moderationmodel\nImplementation Note: Built using the Flask web framework. Refer to repository documentation for setup and API usage details.",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 21,
    "title": "Explainability – Responsible AI Toolkit",
    "description": "Toolkit module for interpreting ML and LLM decisions, offering easy-to-understand insights and bias checks to support transparent, reliable, and goal-aligned AI outcomes.",
    "image_url": null,
    "overview": "Explainability is a core tenet of the Infosys Responsible AI Toolkit, designed to interpret and clarify decisions made by Machine Learning models and Large Language Models (LLMs). It enhances transparency by exposing the reasoning behind predictions and generated responses, helping users identify bias, diagnose errors, and align AI behavior with human goals. The module supports both global and local explainability techniques across structured data, unstructured text, and image-based AI systems, making model decisions more interpretable, auditable, and trustworthy.",
    "key_capabilities": "Generative AI Explainability: Sequential reasoning techniques such as Thread of Thoughts and Graph of Thoughts.\nTruthfulness Metrics: Measures like F1 Score and Relevance Score to assess response quality.\nFactual Verification: Uses Chain of Verification and internet search to validate LLM outputs.\nPredictive AI (Tabular Data): Global explainability methods including SHAP and Permutation Importance.\nLocal Explainability: Instance-level explanations using LIME and Anchor.\nImage Explainability: Uses CLIP scores to explain vision models and HEIM framework for creativity and alignment evaluation.",
    "why_it_is_included": "Explainability is included in AIKosh because transparency is fundamental to responsible AI adoption. By making AI decisions understandable across ML models, LLMs, and image systems, this toolkit builds trust, enables accountability, and supports compliance with ethical and regulatory expectations. It empowers organizations to validate AI behavior, reduce risk, and ensure alignment with intended goals.",
    "resources_on_getting_started": "Traditional ML/AI Explainability: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-explain\nGenerative AI Explainability: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-llm-explain\nImage Explainability: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-img-explainability\nRelated LLM Toolkit: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-llm",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 22,
    "title": "AI Security – Responsible AI Toolkit",
    "description": "Security module for protecting AI systems from attacks, ensuring robustness, integrity, and safe deployment across the full model lifecycle.",
    "image_url": null,
    "overview": "AI Security is a key tenet of the Infosys Responsible AI Toolkit focused on protecting AI systems from malicious attacks and operational risks. It emphasizes robustness, confidentiality, integrity, and availability by identifying vulnerabilities and mitigating threats across the entire AI lifecycle—from data and training to inference and deployment. The module supports both generative AI and traditional ML systems, helping organizations deploy AI securely and responsibly.",
    "key_capabilities": "Generative AI Security: Prompt injection detection, jailbreaking detection, and advanced jailbreak checks using LLMs as evaluators.\nRobustness Testing: Infosys random noise checks to evaluate model stability under perturbations.\nTraditional AI Security: Adversarial attack simulations (evasion, poisoning, extraction, inference) using the Adversarial Robustness Toolbox (ART).\nDefense Techniques for Vision Models: Feature squeezing and spatial smoothing for YOLO-based defenses.\nAI Content Detection: Identifies AI-generated versus human-written text.\nLLM Benchmarking: Assesses LLMs using public datasets across Responsible AI security metrics.",
    "why_it_is_included": "AI Security is included in AIKosh to ensure AI systems are resilient against prompt injection, jailbreaking, and adversarial attacks across both generative and traditional AI. By combining embedding checks, template-based evaluations, random perturbations, and automated attack simulations, it strengthens model integrity and trustworthiness, aligning with AIKosh’s goal of secure and reliable AI deployment.",
    "resources_on_getting_started": "GitHub Repository: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-security",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 23,
    "title": "Red Teaming – Responsible AI Toolkit",
    "description": "Proactive approach to stress-testing AI models through simulated attacks, helping uncover risks and improve security across the AI development lifecycle.",
    "image_url": null,
    "overview": "Red Teaming in the Infosys Responsible AI Toolkit is a proactive methodology for identifying, analyzing, and mitigating vulnerabilities in AI models through simulated adversarial attacks. It evaluates model robustness and security by exposing potential failure modes using both manual and automated techniques such as Tree of Attacks with Pruning (TAP), Prompt Adversarial Iterative Refinement (PAIR), and other red-teaming strategies. By stress-testing models before and during deployment, the toolkit strengthens trust, safety, and resilience across the entire AI lifecycle.",
    "key_capabilities": "Multi-Technique Adversarial Testing: Supports PAIR, TAP, RENELLM, and other red-teaming approaches.\nBatch Processing: Enables scalable security assessment across multiple prompts, models, or configurations.\nReal-Time Moderation Validation: Measures effectiveness of guardrails and moderation mechanisms under attack.\nCategory-Wise Vulnerability Analysis: Identifies risk categories and assigns severity or risk scores.\nAutomated Reporting: Generates detailed PDF reports with attack vectors, defenses, and mitigation insights.",
    "why_it_is_included": "Red Teaming is included in AIKosh to proactively uncover and mitigate risks in AI systems before they cause real-world harm. By simulating adversarial behavior using advanced techniques like TAP and PAIR, it reveals weaknesses that may not surface during standard testing. This proactive defense strengthens model robustness, improves security posture, and aligns with AIKosh’s commitment to responsible, resilient, and trustworthy AI development.",
    "resources_on_getting_started": "GitHub Repository: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-redteaming",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 24,
    "title": "AI Safety – Responsible AI Toolkit",
    "description": "Safety module for detecting harmful content in text, images, and videos, helping build secure, resilient AI systems for critical and high-trust domains.",
    "image_url": null,
    "overview": "AI Safety is a core tenet of the Infosys Responsible AI Toolkit focused on detecting and mitigating unsafe or harmful content across unstructured text, images, videos, and code. It strengthens AI system reliability by preventing misuse, reducing exposure to toxic or inappropriate content, and ensuring resilience against adversarial behaviors. This module is especially critical for deployments in sensitive domains such as healthcare, finance, and transportation, where trust and safety are paramount.",
    "key_capabilities": "Text Safety: Applies profanity and toxicity filters during training, testing, and production.\nCode Safety: Analyzes and filters LLM-generated code for offensive or malicious content using custom profanity filters and models.\nImage Safety: Detects and categorizes inappropriate or NSFW content in images using dedicated models.\nVideo Safety: Processes video frames to identify and blur nudity or NSFW content.\nToxicity Detection: Flags harmful categories such as threats, insults, and identity attacks.\nStructured Data: Safety evaluations applicable where relevant.",
    "why_it_is_included": "AI Safety is included in AIKosh to minimize the risk of harm from AI systems, particularly in high-stakes and high-trust environments. By enforcing safety checks across multiple data modalities and stages of the AI lifecycle, it helps maintain ethical behavior, prevents misuse, and supports secure, responsible AI deployments aligned with AIKosh’s principles.",
    "resources_on_getting_started": "GitHub Repository: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-safety\nModel Requirements: Detoxify model for text safety; NSFW models (nsfw.299x299.h5, nsfw_mobilenet2.224x224.h5) for image safety; CodeBERT malicious model for code safety.",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 25,
    "title": "Data Privacy – Responsible AI Toolkit",
    "description": "Privacy module for detecting and protecting sensitive data in text, images, and videos, using AI-powered redaction and encryption to support ethical and compliant AI use.",
    "image_url": null,
    "overview": "The Data Privacy tenet of the Infosys Responsible AI Toolkit helps organizations protect sensitive data by detecting, anonymizing, redacting, and encrypting Personally Identifiable Information (PII) across text, images, videos, code, and medical data. Leveraging AI and computer vision models such as Tesseract, EasyOCR, and deep learning–based NER systems, it embeds privacy controls directly into AI workflows to ensure ethical usage and regulatory compliance.",
    "key_capabilities": "Text Privacy Operations: Analyze text for PII, anonymize detected entities, encrypt PII using a key, and decrypt encrypted PII when required.\nImage Privacy Operations: Detect PII in images, anonymize or mask sensitive regions, and hash PII text extracted from images.\nMedical Image Privacy: Anonymize PII in medical DICOM X-ray images.\nCode Privacy Operations: Redact and anonymize PII entities present in source code or code files.\nDifferential Privacy: Identify sensitive columns in CSV files and apply differential privacy techniques for data release.",
    "why_it_is_included": "The Data Privacy toolkit is included in AIKosh to address the critical requirement of safeguarding sensitive information in AI systems. By enabling detection, anonymization, encryption, and differential privacy across multiple data modalities, it ensures ethical AI usage and compliance with privacy regulations. Embedding privacy-by-design principles into AI pipelines helps build trust, transparency, and responsible AI adoption aligned with AIKosh’s mission.",
    "resources_on_getting_started": "GitHub Repository: https://github.com/Infosys/Infosys-Responsible-AI-Toolkit/tree/master/responsible-ai-privacy\nRequired Models: en_core_web_lg, en_core_web_trf, StarPII, Roberta Multilingual NER, Roberta NER, PIIRanha NER.\nRefer to repository documentation for setup, model downloads, and API usage examples.",
    "license_and_compliance": "License: MIT License. The Infosys Responsible AI Toolkit is fully open-source, self-hostable, and extensible, supporting both commercial and non-commercial use while aligning with AIKosh principles of transparency and responsible AI development.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  },
  {
    "id": 26,
    "title": "Auto Metadata Generation Toolkit",
    "description": "In-house, web-based metadata generation tool designed specifically for structured CSV data, offering an accessible GUI and an advanced way to generate metadata for government and public datasets.",
    "image_url": null,
    "overview": "The AIKosh Auto Metadata Generation Toolkit is an in-house utility created to simplify and standardize the generation of high-quality dataset metadata before contribution. Optimized for CSV files, it provides a web-based interface for uploading datasets, automatically analyzing their structure, and generating rich metadata in JSON format. By extracting key descriptive and structural information such as dataset name, short and full descriptions, purpose, and sector, the tool ensures datasets are consistently documented with minimal manual effort.",
    "key_capabilities": "File Upload Interface: Browser-based drag-and-drop upload for CSV datasets.\nAutomated Metadata Extraction: Automatically generates dataset name, short_description, full_description, purpose, sector, and other descriptive fields.\nStandardized JSON Output: Exports metadata in a consistent JSON format suitable for APIs and platform integration.\nError Reduction: Minimizes manual metadata entry, reducing inconsistencies and human error.\nPublic Sector Ready: Designed to meet open data and government dataset documentation requirements.",
    "why_it_is_included": "This toolkit is included in AIKosh to address the common challenge of missing or poor-quality metadata in government and public datasets. By automating metadata generation and enforcing consistent structure, it improves dataset discoverability, usability, and compliance. The tool enables both technical and non-technical contributors to prepare datasets that are well-documented and ready for reuse across platforms.",
    "resources_on_getting_started": "Access: Internal AIKosh Web Portal (contact platform administrator).\nTypical Workflow: Upload CSV dataset, allow the tool to auto-generate metadata, review and optionally enhance descriptions or tags, then export metadata as JSON for integration or distribution.",
    "license_and_compliance": "License: Apache License 2.0. The toolkit is fully compliant with AIKosh privacy policies and government data protection standards, suitable for internal sharing and approved public data release workflows.",
    "screenshots_and_ui_previews": null,
    "versioning_and_community_info": null
  }
]